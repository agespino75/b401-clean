{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Chains\n",
    "* Perform several actions in a particular order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80616acf-ae85-4226-ba19-dbbbb9d4796f",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a6725-81b3-4ea3-b39a-eb8f2ded91a2",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 004-chains.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **004-chains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2746c97-9fa5-481c-8333-21de1504a087",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ba351-2cfb-4b93-9c79-3c1100e2e291",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eaf7e9-acf2-4729-b54c-a8fb6ad2ae1a",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a10870-432e-4818-aa5e-6be24c579d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:05.951971Z",
     "start_time": "2025-06-08T05:19:05.943306Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa888f7-3718-4829-8645-30acb43db51f",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d5b71-b26a-4cd5-9765-019077a67141",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM Model\n",
    "* The trend before the launch of chatGPT-4.\n",
    "* See LangChain documentation about LLM Models [here](https://python.langchain.com/v0.1/docs/modules/model_io/llms/)."
   ]
  },
  {
   "cell_type": "code",
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:16.600335Z",
     "start_time": "2025-06-08T05:19:15.910617Z"
    }
   },
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "31346a0c-ee9c-4a80-8e8a-85ef682df7c3",
   "metadata": {},
   "source": [
    "## Chat Model\n",
    "* The general trend after the launch of chatGPT-4.\n",
    "    * Frequently known as \"Chatbot\". \n",
    "    * Conversation between Human and AI.\n",
    "    * Can have a system prompt defining the tone or the role of the AI. \n",
    "* See LangChain documentation about Chat Models [here](https://python.langchain.com/v0.1/docs/modules/model_io/chat/).\n",
    "* By default we will work with ChatOpenAI. See [here](https://python.langchain.com/v0.1/docs/integrations/chat/openai/) the LangChain documentation page about it."
   ]
  },
  {
   "cell_type": "code",
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:20.401167Z",
     "start_time": "2025-06-08T05:19:20.375723Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c2f91601-8594-41d3-9316-d51791fc54e8",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "* See the LangChain documentation about prompts [here](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/).\n",
    "* Input into LLMs.\n",
    "* Prompt templates: easier to use prompts with variables. A prompt template may include:\n",
    "    * instructions,\n",
    "    * few-shot examples,\n",
    "    * and specific context and questions appropriate for a given task."
   ]
  },
  {
   "cell_type": "code",
   "id": "a5383c7e-7e62-46d0-8bef-17ff45a88495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:29.383736Z",
     "start_time": "2025-06-08T05:19:26.350917Z"
    }
   },
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}.\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective=\"curious\", \n",
    "    topic=\"the Kennedy family\"\n",
    ")\n",
    "\n",
    "llmModel.invoke(llmModelPrompt)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIn 1963, just months before President John F. Kennedy was assassinated, a bizarre and mysterious incident occurred involving his brother, Attorney General Robert F. Kennedy.\\n\\nOn a hot summer day in Washington D.C., Robert Kennedy was taking a dip in the pool at his home when he suddenly heard a commotion and screams coming from the Kennedy family\\'s pet orangutan, Charlie. As Robert rushed to the poolside, he found that Charlie had somehow managed to fall into the water and was struggling to stay afloat.\\n\\nWithout hesitation, Robert jumped into the pool and rescued Charlie, pulling him out of the water and onto the pool deck. As he did, he noticed something strange â€“ Charlie was wearing a tiny wetsuit.\\n\\nConfused and amused, the Kennedy family investigated further and discovered that their children\\'s nanny, who often took care of Charlie, had made the wetsuit for the orangutan as a joke. However, no one could explain how Charlie had managed to put on the wetsuit by himself and fall into the pool.\\n\\nThe incident became known as the \"Orangutan Pool Incident\" and became a popular story among the Kennedy family. It was even rumored that President Kennedy himself joked about it, saying that Robert was the only one who could'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "beb7dbcd-524c-4acc-9b65-0b209a170ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:35.725591Z",
     "start_time": "2025-06-08T05:19:34.015248Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"Historian\",\n",
    "    topic=\"The Kennedy family\",\n",
    "    user_input=\"How many grandchildren had Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7585be48-9a19-43ab-a275-8ef6a04246a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:38.879573Z",
     "start_time": "2025-06-08T05:19:38.873198Z"
    }
   },
   "source": [
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 35 grandchildren. He and his wife, Rose Fitzgerald Kennedy, had nine children, and many of those children went on to have multiple children of their own.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 55, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bg2jOibrMIJaVyQrU9J9KFYANbiBy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a36f0f10-a0a4-4eaf-8eeb-019483652f2a-0', usage_metadata={'input_tokens': 55, 'output_tokens': 48, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1373ca0b-342f-4ac6-a697-5e2ad30bfa8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:42.447535Z",
     "start_time": "2025-06-08T05:19:42.444165Z"
    }
   },
   "source": [
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 35 grandchildren. He and his wife, Rose Fitzgerald Kennedy, had nine children, and many of those children went on to have multiple children of their own.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 55, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bg2jOibrMIJaVyQrU9J9KFYANbiBy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a36f0f10-a0a4-4eaf-8eeb-019483652f2a-0' usage_metadata={'input_tokens': 55, 'output_tokens': 48, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "6f6a5e25-e177-4d7a-ba29-6834a6a8152b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:19:46.610743Z",
     "start_time": "2025-06-08T05:19:46.607251Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 35 grandchildren. He and his wife, Rose Fitzgerald Kennedy, had nine children, and many of those children went on to have multiple children of their own.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "a6d770b4-80c5-49a6-a925-de3a800d19f2",
   "metadata": {},
   "source": [
    "#### Old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6dafd17-47a2-4169-992e-76ffb9702d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are an Historian expert on the Kennedy family.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    user_input=\"Name the children and grandchildren of Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a4d5a5a-c3a3-48be-8b31-40b0881faa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Fitzgerald Kennedy had nine children:\n",
      "\n",
      "1. Joseph P. Kennedy Jr.\n",
      "2. John F. Kennedy\n",
      "3. Rosemary Kennedy\n",
      "4. Kathleen Kennedy\n",
      "5. Eunice Kennedy\n",
      "6. Patricia Kennedy\n",
      "7. Robert F. Kennedy\n",
      "8. Jean Kennedy\n",
      "9. Edward M. Kennedy\n",
      "\n",
      "Their grandchildren include:\n",
      "\n",
      "- Caroline Kennedy (daughter of John F. Kennedy)\n",
      "- John F. Kennedy Jr. (son of John F. Kennedy)\n",
      "- Patrick J. Kennedy (son of Edward M. Kennedy)\n",
      "- Robert F. Kennedy Jr. (son of Robert F. Kennedy)\n",
      "- Maria Shriver (daughter of Eunice Kennedy)\n",
      "\n",
      "These are just a few examples of the grandchildren of Joseph P. Kennedy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b510dd0-33b7-4737-aef2-c52a1e8bbf41",
   "metadata": {},
   "source": [
    "#### What is the full potential of ChatPromptTemplate?\n",
    "* Check the [corresponding page](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) in the LangChain API."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:37:25.779829Z",
     "start_time": "2025-06-08T05:37:25.777025Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_core.prompts import FewShotChatMessagePromptTemplate",
   "id": "223a3181d713bf4c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T06:00:02.465829Z",
     "start_time": "2025-06-08T06:00:02.456151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"Â¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"Â¡adiÃ³s!\"},\n",
    "    {\"input\": \"how are you?\", \"output\": \"Â¿cÃ³mo estÃ¡s?\"},\n",
    "    {\"input\": \"what's your name?\", \"output\": \"Â¿cuÃ¡l es tu nombre?\"},\n",
    "    {\"input\": \"I love programming.\", \"output\": \"me encanta programar.\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"output\": \"Â¿cuÃ¡l es la capital de Francia?\"},\n",
    "    {\"input\": \"Translate 'good morning' to Spanish.\", \"output\": \"traduce 'buenos dÃ­as' al espaÃ±ol.\"},\n",
    "    {\"input\": \"Translate 'good night' to Spanish.\", \"output\": \"traduce 'buenas noches' al espaÃ±ol.\"},\n",
    "\n",
    "]"
   ],
   "id": "7475f997e8b341fe",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T06:00:40.233069Z",
     "start_time": "2025-06-08T06:00:39.887122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel\n",
    "\n",
    "response=chain.invoke({\"input\": \"Who was JFK?\"})\n",
    "print(response.content)"
   ],
   "id": "cb4235d858c3b12c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿QuiÃ©n fue JFK?\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "b973d828-0f47-4c43-98ab-e3db306d41e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T06:00:52.501423Z",
     "start_time": "2025-06-08T06:00:51.791376Z"
    }
   },
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel\n",
    "\n",
    "response = chain.invoke({\"input\": \"Who was JFK?\"})\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿QuiÃ©n fue JFK?\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "512a50eb-dfe4-4d08-802e-c3dbc40a3444",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-connect-llms.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 004-chains.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d7c2f-57ed-43f5-b6ed-77c54243c069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
